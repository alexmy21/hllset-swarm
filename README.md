# ğŸ§  HLLSet-Swarm

>*Programmable swarm trajectories via HLLSetâ€“PSO duality*

[![Python](https://img.shields.io/badge/python-3.10+-blue)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/uv/v/hllset_swarm)](https://pypi.org/project/hllset_swarm/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

---

## What it is

HLLSet-Swarm turns the **mathematical duality** between

  - *(a) relational algebra of Chinese-character HLLSets* and  
  - *(b) Particle-Swarm Optimization dynamics*  

into a **declarative GPU kernel compiler** that lets you **script** how a 80 k-dimensional â€œsemantic swarmâ€ should move, converge and **write its final state back** to any external system (LLM, DB, robot, â€¦) as **live feedback**.

Think *â€œGit for meaningâ€* â€“ every trajectory ends with a content-addressed commit that immortalises the swarmâ€™s belief state.

---

## âœ¨ Key features

| Feature | What you get |
|---|---|
| **Duality engine** | PSO guarantees â†’ HLLSet stability proofs |
| **Programmable trajectories** | YAML â†’ GPU sparse kernels (no CUDA code) |
| **Recursive meta-swarm** | swarm-of-swarms for higher-order abstraction |
| **Git backend** | every layer is a `.pt.zst` blob pushed to Github |
| **Environment adapters** | OpenAI, SQL, ROS, stdout â€¦ plug your own |
| **Laptopâ†’data-center** | 80 k dims run in < 1 GB VRAM (RTX 3060 ready) |

---

## âš¡ 30-second demo

```bash
git clone https://github.com/alexmy21/hllset_swarm.git
cd hllset_swarm
uv add -e .
export GITHUB_TOKEN="ghp_xxx"
```

```python
from hllset_swarm import SwarmProgram, Environment

env = Environment(text="äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ")
prog = SwarmProgram.from_yaml("trajectories/default.yml")
prog.run(env)                       # â† GPU kernel executes
prog.commit_to_github("user/cortex", token=os.getenv("GITHUB_TOKEN"))
print("embedding shape:", env.embedding.shape)  # (80000,)
```

---

## ğŸ“ Repository layout

```bash
hllset_swarm/
â”œâ”€â”€ src/hllset_swarm/
â”‚   â”œâ”€â”€ kernel.py          # immutable Chinese-character HLLSets
â”‚   â”œâ”€â”€ lattice.py         # BSS Ï„-Ï sparse matrices
â”‚   â”œâ”€â”€ swarm.py           # GPU resident SwarmState
â”‚   â”œâ”€â”€ trajectory.py      # YAML â†’ kernel compiler
â”‚   â”œâ”€â”€ cortex.py          # recursive meta-swarm
â”‚   â””â”€â”€ io/
â”‚       â”œâ”€â”€ github.py      # Github Contents API backend
â”‚       â””â”€â”€ env.py         # adapters for external systems
â”œâ”€â”€ trajectories/          # ready-made scripts
â”‚   â”œâ”€â”€ default.yml
â”‚   â””â”€â”€ meta_swarm.yml
â”œâ”€â”€ tests/
â””â”€â”€ examples/
    â”œâ”€â”€ notebook.ipynb
    â””â”€â”€ ros_talker.py
```

---

## ğŸ› ï¸ Installation

### Using `uv` (fastest)

```bash
uv add hllset_swarm
```

### From source

```bash
git clone https://github.com/yourname/hllset_swarm.git
cd hllset_swarm
uv add -e .
```

### Julia dependency (only for HLLSet backend)

```bash
# one-liner installer
curl -fsSL https://install.julialang.org | sh
julia -e 'using Pkg; Pkg.add("HllSets")'
```

---

## ğŸ¯ Concepts in one picture

```text
Chinese text
     â”‚
     â–¼
[HLLSet cover]  â”€â”€BSS Ï„-Ïâ”€â”€â–º  GPU SwarmState  â”€â”€convergeâ”€â”€â–º  s(t+1)
     â–²                                                    â”‚
     â”‚              PSO-HLLSet duality                    â–¼
Environment  â—„â”€â”€feedbackâ”€â”€  Github commit  â—„â”€â”€layer blobâ”€â”€â”˜
```

---

## ğŸ“ Writing a trajectory

`trajectories/default.yml`

```yaml
name: chinese_cover
kernel: 80k_ccd.json.gz
precision: 10               # 1024 registers

params:
  alpha: 0.20
  beta:  0.15
  gamma: 0.05
  eta:   0.02

trajectory:
  - op: reset
    value: 0.5
  - op: cover        # push entry cover into swarm
    entry: "{{ env.text }}"
  - op: converge
    max_steps: 5
    tol: 1e-3
  - op: feedback
    target: env.embedding   # write s(t+1) back
```

Run it:

```python
prog = SwarmProgram.from_yaml("trajectories/default.yml")
prog.run(env)
```

---

## ğŸ² Controlled noise â€“ low-precision hash as regularizer

| Precision | Collision rate | Use-case | Noise role |
|---|---|---|---|
| **64 bit** | < 0.1 % | production Chinese | almost deterministic |
| **32 bit** | â‰ˆ 1 % | mobile emoji | **mild regulariser** |
| **16 bit** | â‰ˆ 6 % | MCU controller | **strong regulariser** |
| **8 bit** | â‰ˆ 30 % | toy demos | **extreme dropout** |

**Interpretation**:

- **High collision** = **bit-dropout** â†’ union **looks bigger** than reality.  
- **Multi-seed triangulation** = **denoising U-Net** â†’ recover **true cover**.

---

## ğŸ§  Denoising analogy (vision â†’ semantics)

| Vision pipeline | Semantic pipeline |
|---|---|
| **Gaussian noise** | **hash collision dropout** |
| **Noisy image** | **noisy HLLSet union** |
| **U-Net denoiser** | **multi-seed Hopfield descent** |
| **Clean image** | **disambiguated cover** |

**Same math**, **different substrate**.

---

## ğŸ”Œ Environment adapters

| Adapter | Description |
|---|---|
| `OpenAIAdapter` | write embedding into system prompt |
| `SQLAdapter` | store vector in Postgres `VECTOR` column |
| `ROSAdapter` | publish `Float32MultiArray` on `/semantic_state` |
| `StdoutAdapter` | debug JSON to console |

Add your own:

```python
from hllset_swarm.io import BaseAdapter
class MyAdapter(BaseAdapter):
    def update_embedding(self, vec: np.ndarray):
        requests.post("http://my.api/embedding", data=vec.tobytes())
```

---

## ğŸ“Š Hardware requirements

| Component | Size | Note |
|---|---|---|
| Chinese kernel (80 k) | 160 MB | memory-mapped |
| Sparse WÏ„ / WÏ | 2 Ã— 200 MB | half-precision |
| GPU working set | < 6 GB | RTX 3060 12 GB âœ… |
| One layer commit | 1-3 MB | zstd compressed |

---

## ğŸ“ˆ Performance

| Metric | RTX 3060 | A100 80 GB |
|---|---|---|
| Single swarm step | 0.8 ms | 0.15 ms |
| 5-step trajectory | 4.2 ms | 0.8 ms |
| Layer commit + upload | 0.3 s | 0.2 s |

---

## ğŸ§ª Tests

```bash
uv run pytest tests/
```

---

## ğŸš¦ Roadmap

| Month | Milestone | Status |
|---|---|---|
| **November 2025** | âœ… **PoC on 300-char dictionary** | DONE |
| **November 2025** | âœ… **Julia backend + GPU kernels** | DONE |
| **December 2025** | **Goal: 80 k kernel + sparse lattice** | ğŸš§  |
| **December 2025** | **Goal: programmable YAML trajectories** | ğŸ“‹ |
| **January 2026** | **Goal: Git-commit cortex layers** | ğŸ“‹ |
| **January 2026** | **Goal: environment adapters (LLM, DB, ROS)** | ğŸ“‹ |
| **January 2026** | **Goal: first kibbutz (3-node collective)** | ğŸ¯ |

---

### ğŸ”­ Next giant leap â€“ **SGS.ai Kibbutz**

> â€œThe same maths that describes birds finding food describes bits finding meaning.â€  
> We now let **those bits farm together**.

| Kibbutz Feature | Description | Target Date |
|---|---|---|
| **Radical sharding** | conflict-free parallel farming | Jan 2026 |
| **CRDT consensus** | arithmetic-mean lattice merge | Feb 2026 |
| **Host-score income** | Hebb burn proportional to BLEU/RLHF | Q1 2026 |
| **Elastic scale** | join/leave without downtime | Q1 2026 |
| **Cross-domain kibbutz** | Chinese + Arabic + English swarms | Q2 2026 |

---

## ğŸŒ Beyond Chinese â€“ any *"hieroglyphic"* substrate

Chinese is **our first substrate** because it is **optimally hieroglyphic**:

- finite, standardised inventory (â‰ˆ 80 k)  
- unambiguous dictionary definitions **in the same language**  
- clear **radicalâ†’characterâ†’word** composition rules  
- 3 000 years of **continuous semantic fossil record**

But the **mathematics is substrate-agnostic**.  
Any symbol set that satisfies **four axioms** can be dropped in:

1. **Non-inflectional** (no paradigms, no declensions)  
2. **Compositionally closed** (complex = stack of simples)  
3. **Lexicographically frozen** (each symbol has **one** normative definition)  
4. **Hashable** (deterministic bit-pattern from symbol)

---

### ğŸ§ª Substrates on the roadmap

| Substrate | Inventory | Composition unit | Status | ETA |
|---|---|---|---|---|
| **Chinese (CCD)** | 80 k chars | radical | âœ… reference | now |
| **Classic Maya glyphs** | 1 100 glyphs | block | ğŸš§ POC | Q4 2025 |
| **Emoji 15.1** | 3 782 emojis | ZWJ sequence | ğŸ“‹ design | Q1 2026 |
| **Minecraft blocks** | 1 500 blocks | voxel neighbour | ğŸ“‹ design | Q1 2026 |
| **AI Esperanto** | 10 k morphemes | concat-rule | ğŸ“‹ white-paper | Q2 2026 |

---

### ğŸ•¹ï¸ Example â€“ Minecraft substrate (sketch)

```yaml
substrate: minecraft
inventory: minecraft_blocks.json.gz
precision: 12          # 4096 registers
hash_seed: "mc1.20.1"
composition_rule: "6-face-voxel+up/down"
definition_source: "block_state.properties"
```

- **Block** â†’ HLLSet hashed from **block-state NBT**  
- **Structure** â†’ union of block HLLSets  
- **Scene embedding** â†’ swarm convergence on block-cover

Same YAML, same GPU kernel, **different universe**.

---

## ğŸ¤ Contributing

1. Fork  
2. `uv add -e .`  
3. `uv run pytest`  
4. PR against `main`

We love **new adapters** and **trajectory recipes**!

---

## ğŸ“„ Citation

```bibtex
@software{hllset_swarm,
  title = {HLLSet-Swarm: Programmable Swarm Trajectories via HLLSet--PSO Duality},
  author = {Alex Mylnikov, Aleksandr Solonin},
  url = {https://github.com/alexmy21/hllset_swarm},
  year = {2025}
}
```

---

## ğŸ“œ License

MIT â€“ see [LICENSE](LICENSE).

---

**Star â­ the repo if you want Git to remember meaning for you.**

## Reference

1. [Check project wiki for more information](https://github.com/alexmy21/hllset-swarm/wiki)
2. [U-Net](https://arxiv.org/pdf/1505.04597)
3. [U-Net medium](https://medium.com/@keremturgutlu/semantic-segmentation-u-net-part-1-d8d6f6005066)
4. [Kalman Filters in Python](https://medium.com/@ccpythonprogramming/particle-filters-in-python-when-kalman-filters-break-down-75d51550ee15)
5. [Umbral Calculus](https://www.cantorsparadise.com/the-dark-art-of-umbral-calculus-976959da72ca)
