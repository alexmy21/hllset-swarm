# üß† HLLSet-Swarm

>*Programmable swarm trajectories via HLLSet‚ÄìPSO duality*

[![Python](https://img.shields.io/badge/python-3.10+-blue)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/uv/v/hllset_swarm)](https://pypi.org/project/hllset_swarm/)
[![License](https://img.shields.io/badge/license-MIT-green)](LICENSE)

---

## What it is

HLLSet-Swarm turns the **mathematical duality** between

  - *(a) relational algebra of Chinese-character HLLSets* and  
  - *(b) Particle-Swarm Optimization dynamics*  

into a **declarative GPU kernel compiler** that lets you **script** how a 80 k-dimensional ‚Äúsemantic swarm‚Äù should move, converge and **write its final state back** to any external system (LLM, DB, robot, ‚Ä¶) as **live feedback**.

Think *‚ÄúGit for meaning‚Äù* ‚Äì every trajectory ends with a content-addressed commit that immortalises the swarm‚Äôs belief state.

---

## ‚ú® Key features

| Feature | What you get |
|---|---|
| **Duality engine** | PSO guarantees ‚Üí HLLSet stability proofs |
| **Programmable trajectories** | YAML ‚Üí GPU sparse kernels (no CUDA code) |
| **Recursive meta-swarm** | swarm-of-swarms for higher-order abstraction |
| **Git backend** | every layer is a `.pt.zst` blob pushed to Github |
| **Environment adapters** | OpenAI, SQL, ROS, stdout ‚Ä¶ plug your own |
| **Laptop‚Üídata-center** | 80 k dims run in < 1 GB VRAM (RTX 3060 ready) |

---

## ‚ö° 30-second demo

```bash
git clone https://github.com/alexmy21/hllset_swarm.git
cd hllset_swarm
uv add -e .
export GITHUB_TOKEN="ghp_xxx"
```

```python
from hllset_swarm import SwarmProgram, Environment

env = Environment(text="‰∫∫Â∑•Êô∫ËÉΩÊ≠£Âú®ÊîπÂèò‰∏ñÁïå")
prog = SwarmProgram.from_yaml("trajectories/default.yml")
prog.run(env)                       # ‚Üê GPU kernel executes
prog.commit_to_github("user/cortex", token=os.getenv("GITHUB_TOKEN"))
print("embedding shape:", env.embedding.shape)  # (80000,)
```

---

## üìÅ Repository layout

```bash
hllset_swarm/
‚îú‚îÄ‚îÄ src/hllset_swarm/
‚îÇ   ‚îú‚îÄ‚îÄ kernel.py          # immutable Chinese-character HLLSets
‚îÇ   ‚îú‚îÄ‚îÄ lattice.py         # BSS œÑ-œÅ sparse matrices
‚îÇ   ‚îú‚îÄ‚îÄ swarm.py           # GPU resident SwarmState
‚îÇ   ‚îú‚îÄ‚îÄ trajectory.py      # YAML ‚Üí kernel compiler
‚îÇ   ‚îú‚îÄ‚îÄ cortex.py          # recursive meta-swarm
‚îÇ   ‚îî‚îÄ‚îÄ io/
‚îÇ       ‚îú‚îÄ‚îÄ github.py      # Github Contents API backend
‚îÇ       ‚îî‚îÄ‚îÄ env.py         # adapters for external systems
‚îú‚îÄ‚îÄ trajectories/          # ready-made scripts
‚îÇ   ‚îú‚îÄ‚îÄ default.yml
‚îÇ   ‚îî‚îÄ‚îÄ meta_swarm.yml
‚îú‚îÄ‚îÄ tests/
‚îî‚îÄ‚îÄ examples/
    ‚îú‚îÄ‚îÄ notebook.ipynb
    ‚îî‚îÄ‚îÄ ros_talker.py
```

---

## üõ†Ô∏è Installation

### Using `uv` (fastest)

```bash
uv add hllset_swarm
```

### From source

```bash
git clone https://github.com/yourname/hllset_swarm.git
cd hllset_swarm
uv add -e .
```

### Julia dependency (only for HLLSet backend)

```bash
# one-liner installer
curl -fsSL https://install.julialang.org | sh
julia -e 'using Pkg; Pkg.add("HllSets")'
```

---

## üéØ Concepts in one picture

```text
Chinese text
     ‚îÇ
     ‚ñº
[HLLSet cover]  ‚îÄ‚îÄBSS œÑ-œÅ‚îÄ‚îÄ‚ñ∫  GPU SwarmState  ‚îÄ‚îÄconverge‚îÄ‚îÄ‚ñ∫  s(t+1)
     ‚ñ≤                                                    ‚îÇ
     ‚îÇ              PSO-HLLSet duality                    ‚ñº
Environment  ‚óÑ‚îÄ‚îÄfeedback‚îÄ‚îÄ  Github commit  ‚óÑ‚îÄ‚îÄlayer blob‚îÄ‚îÄ‚îò
```

---

## üìù Writing a trajectory

`trajectories/default.yml`

```yaml
name: chinese_cover
kernel: 80k_ccd.json.gz
precision: 10               # 1024 registers

params:
  alpha: 0.20
  beta:  0.15
  gamma: 0.05
  eta:   0.02

trajectory:
  - op: reset
    value: 0.5
  - op: cover        # push entry cover into swarm
    entry: "{{ env.text }}"
  - op: converge
    max_steps: 5
    tol: 1e-3
  - op: feedback
    target: env.embedding   # write s(t+1) back
```

Run it:

```python
prog = SwarmProgram.from_yaml("trajectories/default.yml")
prog.run(env)
```

---

## üé≤ Controlled noise ‚Äì low-precision hash as regularizer

| Precision | Collision rate | Use-case | Noise role |
|---|---|---|---|
| **64 bit** | < 0.1 % | production Chinese | almost deterministic |
| **32 bit** | ‚âà 1 % | mobile emoji | **mild regulariser** |
| **16 bit** | ‚âà 6 % | MCU controller | **strong regulariser** |
| **8 bit** | ‚âà 30 % | toy demos | **extreme dropout** |

**Interpretation**:

- **High collision** = **bit-dropout** ‚Üí union **looks bigger** than reality.  
- **Multi-seed triangulation** = **denoising U-Net** ‚Üí recover **true cover**.

---

## üß† Denoising analogy (vision ‚Üí semantics)

| Vision pipeline | Semantic pipeline |
|---|---|
| **Gaussian noise** | **hash collision dropout** |
| **Noisy image** | **noisy HLLSet union** |
| **U-Net denoiser** | **multi-seed Hopfield descent** |
| **Clean image** | **disambiguated cover** |

**Same math**, **different substrate**.

---

## üîå Environment adapters

| Adapter | Description |
|---|---|
| `OpenAIAdapter` | write embedding into system prompt |
| `SQLAdapter` | store vector in Postgres `VECTOR` column |
| `ROSAdapter` | publish `Float32MultiArray` on `/semantic_state` |
| `StdoutAdapter` | debug JSON to console |

Add your own:

```python
from hllset_swarm.io import BaseAdapter
class MyAdapter(BaseAdapter):
    def update_embedding(self, vec: np.ndarray):
        requests.post("http://my.api/embedding", data=vec.tobytes())
```

---

## üìä Hardware requirements

| Component | Size | Note |
|---|---|---|
| Chinese kernel (80 k) | 160 MB | memory-mapped |
| Sparse WœÑ / WœÅ | 2 √ó 200 MB | half-precision |
| GPU working set | < 6 GB | RTX 3060 12 GB ‚úÖ |
| One layer commit | 1-3 MB | zstd compressed |

---

## üìà Performance

| Metric | RTX 3060 | A100 80 GB |
|---|---|---|
| Single swarm step | 0.8 ms | 0.15 ms |
| 5-step trajectory | 4.2 ms | 0.8 ms |
| Layer commit + upload | 0.3 s | 0.2 s |

---

## üß™ Tests

```bash
uv run pytest tests/
```

---

## üö¶ Roadmap

| Month | Milestone | Status |
|---|---|---|
| **November 2025** | ‚úÖ **PoC on 300-char dictionary** | DONE |
| **November 2025** | ‚úÖ **Julia backend + GPU kernels** | DONE |
| **December 2025** | **Goal: 80 k kernel + sparse lattice** | üöß  |
| **December 2025** | **Goal: programmable YAML trajectories** | üìã |
| **January 2026** | **Goal: Git-commit cortex layers** | üìã |
| **January 2026** | **Goal: environment adapters (LLM, DB, ROS)** | üìã |
| **January 2026** | **Goal: first kibbutz (3-node collective)** | üéØ |

---

### üî≠ Next giant leap ‚Äì **SGS.ai Kibbutz**

> ‚ÄúThe same maths that describes birds finding food describes bits finding meaning.‚Äù  
> We now let **those bits farm together**.

| Kibbutz Feature | Description | Target Date |
|---|---|---|
| **Radical sharding** | conflict-free parallel farming | Jan 2026 |
| **CRDT consensus** | arithmetic-mean lattice merge | Feb 2026 |
| **Host-score income** | Hebb burn proportional to BLEU/RLHF | Q1 2026 |
| **Elastic scale** | join/leave without downtime | Q1 2026 |
| **Cross-domain kibbutz** | Chinese + Arabic + English swarms | Q2 2026 |

---

## üåç Beyond Chinese ‚Äì any *"hieroglyphic"* substrate

Chinese is **our first substrate** because it is **optimally hieroglyphic**:

- finite, standardised inventory (‚âà 80 k)  
- unambiguous dictionary definitions **in the same language**  
- clear **radical‚Üícharacter‚Üíword** composition rules  
- 3 000 years of **continuous semantic fossil record**

But the **mathematics is substrate-agnostic**.  
Any symbol set that satisfies **four axioms** can be dropped in:

1. **Non-inflectional** (no paradigms, no declensions)  
2. **Compositionally closed** (complex = stack of simples)  
3. **Lexicographically frozen** (each symbol has **one** normative definition)  
4. **Hashable** (deterministic bit-pattern from symbol)

---

### üß™ Substrates on the roadmap

| Substrate | Inventory | Composition unit | Status | ETA |
|---|---|---|---|---|
| **Chinese (CCD)** | 80 k chars | radical | ‚úÖ reference | now |
| **Classic Maya glyphs** | 1 100 glyphs | block | üöß POC | Q4 2025 |
| **Emoji 15.1** | 3 782 emojis | ZWJ sequence | üìã design | Q1 2026 |
| **Minecraft blocks** | 1 500 blocks | voxel neighbour | üìã design | Q1 2026 |
| **AI Esperanto** | 10 k morphemes | concat-rule | üìã white-paper | Q2 2026 |

---

### üïπÔ∏è Example ‚Äì Minecraft substrate (sketch)

```yaml
substrate: minecraft
inventory: minecraft_blocks.json.gz
precision: 12          # 4096 registers
hash_seed: "mc1.20.1"
composition_rule: "6-face-voxel+up/down"
definition_source: "block_state.properties"
```

- **Block** ‚Üí HLLSet hashed from **block-state NBT**  
- **Structure** ‚Üí union of block HLLSets  
- **Scene embedding** ‚Üí swarm convergence on block-cover

Same YAML, same GPU kernel, **different universe**.

---

## ü§ù Contributing

1. Fork  
2. `uv add -e .`  
3. `uv run pytest`  
4. PR against `main`

We love **new adapters** and **trajectory recipes**!

---

## üìÑ Citation

```bibtex
@software{hllset_swarm,
  title = {HLLSet-Swarm: Programmable Swarm Trajectories via HLLSet--PSO Duality},
  author = {Alex Mylnikov, Aleksandr Solonin},
  url = {https://github.com/alexmy21/hllset_swarm},
  year = {2025}
}
```

---

## üìú License

MIT ‚Äì see [LICENSE](LICENSE).

---

**Star ‚≠ê the repo if you want Git to remember meaning for you.**

## References

1. [Check project wiki for more information](https://github.com/alexmy21/hllset-swarm/wiki)
2. [U-Net](https://arxiv.org/pdf/1505.04597)
3. [U-Net medium](https://medium.com/@keremturgutlu/semantic-segmentation-u-net-part-1-d8d6f6005066)
4. [Kalman Filters in Python](https://medium.com/@ccpythonprogramming/particle-filters-in-python-when-kalman-filters-break-down-75d51550ee15)
5. [Umbral Calculus](https://www.cantorsparadise.com/the-dark-art-of-umbral-calculus-976959da72ca)
6. [Bell: The Theorem That Proved Einstein Wrong](https://medium.com/@manaritaa/coffee-with-bell-the-theorem-that-proved-einstein-wrong-cddc77522885)
7. [Less is More: Recursive Reasoning with Tiny Networks](https://arxiv.org/pdf/2510.04871)
8. [BLEU](https://en.wikipedia.org/wiki/BLEU)
9. [Gated Attention for Large Language Models](https://openreview.net/pdf?id=1b7whO4SfY)
10. [Spectral Theory for DAG](https://isamu-website.medium.com/understanding-spectral-graph-theory-for-dags-7ca767cec122)
11. [Linear Mathematics as Unified Cognitive Space](https://medium.com/@tomkob99_89317/linear-mathematics-as-unified-cognitive-space-from-fragmented-knowledge-to-structural-clarity-d1f0738d6528)
12. [Towards Enterprise-Ready Computer Using Generalist Agent](https://arxiv.org/pdf/2503.01861)
13. [Probability-density-is-not-an-extension-of-probability-mass](https://medium.com/@tomkob99_89317/probability-density-is-not-an-extension-of-probability-mass-but-average-unites-them-021aba877035)
14. [Recursive-Categorical-Framework](https://github.com/calisweetleaf/recursive-categorical-framework)
15. [HLLSet Communication](https://chat.deepseek.com/share/w08kirq9m9mlkiidex)
